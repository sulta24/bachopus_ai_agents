# AI Orchestrator

A sophisticated multi-agent AI system for intelligent data analysis and external API orchestration with advanced reasoning capabilities.

## Table of Contents

- [Overview](#overview)
- [System Architecture](#system-architecture)
- [Key Features](#key-features)
- [Quick Start](#quick-start)
- [API Documentation](#api-documentation)
- [Configuration](#configuration)
- [System Components](#system-components)
- [Development](#development)
- [Troubleshooting](#troubleshooting)
- [Performance](#performance)

## Overview

AI Orchestrator is an enterprise-grade intelligent system that implements a three-phase reasoning approach (Planning â†’ Execution â†’ Feedback) to process complex queries and orchestrate interactions with external services like Datadog. The system uses specialized agents and LLM-powered analysis to provide comprehensive insights and recommendations.

### Core Capabilities

- **Multi-Phase Processing**: Structured reasoning through planning, execution, and feedback phases
- **Datadog Integration**: Real-time metrics retrieval and time-series data analysis
- **Intelligent Context Formatting**: Adaptive data processing and context optimization
- **Bearer Token Authentication**: Enterprise-grade security for API interactions
- **RESTful API**: Standards-compliant interface for seamless integration
- **Reasoning Traceability**: Complete audit trail of decision-making processes

## System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Client App    â”‚â”€â”€â”€â–¶â”‚   FastAPI Server â”‚â”€â”€â”€â–¶â”‚  AI Orchestrator â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                          â”‚
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚                                 â–¼                                 â”‚
                        â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
                        â”‚                    â”‚   Reasoning State   â”‚                       â”‚
                        â”‚                    â”‚   Management        â”‚                       â”‚
                        â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
                        â”‚                                 â”‚                                 â”‚
                        â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
                        â”‚         â”‚                       â”‚                       â”‚         â”‚
                        â”‚         â–¼                       â–¼                       â–¼         â”‚
                        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
                        â”‚  â”‚  PLANNING   â”‚      â”‚   EXECUTION     â”‚      â”‚  FEEDBACK   â”‚   â”‚
                        â”‚  â”‚   Phase     â”‚      â”‚    Phase        â”‚      â”‚   Phase     â”‚   â”‚
                        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
                        â”‚         â”‚                       â”‚                       â”‚         â”‚
                        â”‚         â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚         â”‚
                        â”‚         â”‚              â”‚        â”‚        â”‚              â”‚         â”‚
                        â”‚         â”‚              â–¼        â–¼        â–¼              â”‚         â”‚
                        â”‚         â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚         â”‚
                        â”‚         â”‚      â”‚     External Integrations      â”‚      â”‚         â”‚
                        â”‚         â”‚      â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚      â”‚         â”‚
                        â”‚         â”‚      â”‚  â”‚Datadog  â”‚ â”‚Backend APIs â”‚   â”‚      â”‚         â”‚
                        â”‚         â”‚      â”‚  â”‚Client   â”‚ â”‚   Client    â”‚   â”‚      â”‚         â”‚
                        â”‚         â”‚      â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚      â”‚         â”‚
                        â”‚         â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚         â”‚
                        â”‚         â”‚                       â”‚                       â”‚         â”‚
                        â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
                        â”‚                                 â”‚                                 â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                          â–¼
                                                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                â”‚   Response      â”‚
                                                â”‚ + Trace Data    â”‚
                                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Key Features

### ğŸ§  **Advanced AI Reasoning**
- Three-phase processing pipeline with structured reasoning
- LLM-powered analysis with context-aware prompting
- Adaptive system prompts for different processing phases
- Comprehensive reasoning trace generation

### ğŸ”— **External Service Integration**
- **Datadog API**: Metrics retrieval, time-series analysis, service monitoring
- **Backend Services**: RESTful API communication with error handling
- **Authentication**: Bearer token and API key management
- **Rate Limiting**: Built-in request throttling and retry mechanisms

### ğŸ“Š **Data Processing**
- Intelligent context formatting and data structuring
- JSON parsing with fallback mechanisms
- Large dataset handling with memory optimization
- Real-time data streaming capabilities

### ğŸ”’ **Security & Reliability**
- Environment-based configuration management
- Secure API key handling and rotation
- Comprehensive error handling and logging
- Production-ready minimal logging configuration

## Quick Start

### Prerequisites

- Python 3.8+
- OpenAI API access
- Datadog API credentials (optional)

### Installation

```bash
# Clone the repository
git clone <repository-url>
cd AI_Orchestrator

# Create virtual environment
python -m venv venv

# Activate virtual environment
# Windows
venv\Scripts\activate
# Linux/Mac
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### Configuration

1. **Environment Setup**:
```bash
# Copy environment template
cp .env.example .env
```

2. **Configure Environment Variables**:
```env
# Required
OPENAI_API_KEY=sk-proj-your-openai-key-here

# Optional - Datadog Integration
DATADOG_API_KEY=your-datadog-api-key
DATADOG_APP_KEY=your-datadog-app-key
DATADOG_SITE=datadoghq.com

# Optional - Backend Services
BACKEND_API_URL=https://your-backend-api.com
BACKEND_API_TOKEN=your-backend-token
```

### Launch

```bash
# Development server
uvicorn main:app --reload --port 8000

# Production server
uvicorn main:app --host 0.0.0.0 --port 8000 --workers 4
```

## API Documentation

### Authentication

All API endpoints require Bearer token authentication:

```bash
Authorization: Bearer <your-token>
```

### Core Endpoint

#### `POST /orchestrate`

Process intelligent queries with multi-phase reasoning.

**Request Headers:**
```
Authorization: Bearer <token>
Content-Type: application/json
```

**Request Body:**
```json
{
  "service_id": "production-api",
  "session_id": "user-session-123",
  "user_message": "Analyze system performance and identify bottlenecks"
}
```

**Response:**
```json
{
  "answer": "Based on the analysis of your system metrics, I've identified several performance bottlenecks:\n\n1. **Database Query Performance**: Average response time has increased by 45% over the past hour\n2. **Memory Usage**: Current utilization at 87%, approaching critical threshold\n3. **API Response Times**: 95th percentile latency exceeds SLA by 200ms\n\nRecommendations:\n- Optimize database indexes for frequently accessed tables\n- Scale memory resources or implement caching layer\n- Review and optimize slow API endpoints",
  "session_id": "user-session-123",
  "timestamp": "2024-01-19T15:30:45.123Z",
  "reasoning_trace": {
    "total_steps": 8,
    "execution_time_ms": 2340,
    "phases": ["planning", "execution", "feedback"],
    "confidence_score": 0.92
  }
}
```

### Example Use Cases

#### 1. System Performance Analysis
```bash
curl -X POST "http://localhost:8000/orchestrate" \
  -H "Authorization: Bearer your-token" \
  -H "Content-Type: application/json" \
  -d '{
    "service_id": "web-app",
    "session_id": "perf-analysis-001",
    "user_message": "Check CPU and memory usage trends for the last 24 hours"
  }'
```

#### 2. Error Investigation
```bash
curl -X POST "http://localhost:8000/orchestrate" \
  -H "Authorization: Bearer your-token" \
  -H "Content-Type: application/json" \
  -d '{
    "service_id": "api-gateway",
    "session_id": "error-investigation-002",
    "user_message": "Investigate recent 5xx errors and their root causes"
  }'
```

#### 3. Capacity Planning
```bash
curl -X POST "http://localhost:8000/orchestrate" \
  -H "Authorization: Bearer your-token" \
  -H "Content-Type: application/json" \
  -d '{
    "service_id": "database-cluster",
    "session_id": "capacity-planning-003",
    "user_message": "Analyze current resource utilization and predict scaling needs"
  }'
```

## Configuration

### Environment Variables

| Variable | Required | Description | Example |
|----------|----------|-------------|---------|
| `OPENAI_API_KEY` | Yes | OpenAI API key for LLM operations | `sk-proj-...` |
| `DATADOG_API_KEY` | No | Datadog API key for metrics | `abc123...` |
| `DATADOG_APP_KEY` | No | Datadog application key | `def456...` |
| `DATADOG_SITE` | No | Datadog site (default: datadoghq.com) | `datadoghq.eu` |
| `BACKEND_API_URL` | No | Backend service base URL | `https://api.example.com` |
| `BACKEND_API_TOKEN` | No | Backend service auth token | `bearer-token-123` |
| `LOG_LEVEL` | No | Logging level (default: ERROR) | `INFO`, `DEBUG` |

### Advanced Configuration

Create `config.json` for advanced settings:

```json
{
  "orchestrator": {
    "max_reasoning_steps": 10,
    "timeout_seconds": 30,
    "retry_attempts": 3
  },
  "datadog": {
    "default_timeframe": "1h",
    "max_metrics_per_request": 100
  },
  "llm": {
    "model": "gpt-4",
    "temperature": 0.1,
    "max_tokens": 2000
  }
}
```

## System Components

### Core Components

#### **AIOrchestrator** (`core/orchestrator.py`)
Central coordination engine that manages the three-phase reasoning process:

- **Planning Phase**: Query analysis and strategy formulation
- **Execution Phase**: Data gathering and processing
- **Feedback Phase**: Result synthesis and recommendation generation

**Key Methods:**
```python
async def process_query(query: str, context: Dict) -> ProcessingResult
async def _planning_phase(state: ReasoningState) -> PlanningResult
async def _execution_phase(state: ReasoningState) -> ExecutionResult
async def _feedback_phase(state: ReasoningState) -> FeedbackResult
```

#### **BackendClient** (`core/backend_client.py`)
Handles communication with external backend services:

- RESTful API communication with retry logic
- Authentication token management
- Response parsing and error handling
- Rate limiting and request throttling

**Key Methods:**
```python
async def get_service_info(service_id: str) -> ServiceInfo
async def get_chat_messages(session_id: str) -> List[Message]
async def add_message(session_id: str, message: Message) -> bool
```

#### **DatadogClient** (`core/datadog_client.py`)
Specialized client for Datadog API integration:

- Metrics retrieval and time-series analysis
- Service monitoring and alerting data
- Custom query execution
- Data aggregation and filtering

**Key Methods:**
```python
async def get_metrics(query: str, timeframe: str) -> MetricsData
async def get_service_summary(service: str) -> ServiceSummary
async def query_timeseries(metric: str, tags: List[str]) -> TimeSeriesData
```

### Supporting Components

#### **ReasoningState** (`core/reasoning_state.py`)
State management for reasoning processes:

```python
@dataclass
class ReasoningState:
    session_id: str
    user_query: str
    current_phase: ReasoningPhase
    context_data: Dict[str, Any]
    reasoning_steps: List[ReasoningStep]
    confidence_scores: Dict[str, float]
    execution_metadata: ExecutionMetadata
```

#### **ContextFormatter** (`core/context_formatter.py`)
Intelligent data formatting and context optimization:

- Large dataset summarization
- JSON structure optimization
- Context window management
- Data relevance scoring

## Development

### Testing

```bash
# Test API connectivity
python test_api_key.py

# Test Datadog integration
python test_datadog.py

# Run unit tests
python -m pytest tests/ -v

# Run integration tests
python -m pytest tests/integration/ -v
```

### Development Server

```bash
# Start with hot reload
uvicorn main:app --reload --port 8000 --log-level debug

# Enable detailed logging
export LOG_LEVEL=DEBUG
uvicorn main:app --reload --port 8000
```

### Code Quality

```bash
# Format code
black .

# Lint code
flake8 .

# Type checking
mypy .
```

## Troubleshooting

### Common Issues

#### 1. **OpenAI API Errors**
```
Error: Invalid API key or quota exceeded
```
**Solution:**
- Verify `OPENAI_API_KEY` in `.env`
- Check API quota and billing status
- Ensure API key has required permissions

#### 2. **Datadog Connection Issues**
```
Error: Failed to connect to Datadog API
```
**Solution:**
- Verify `DATADOG_API_KEY` and `DATADOG_APP_KEY`
- Check network connectivity to Datadog endpoints
- Validate API key permissions for metrics access

#### 3. **Memory Issues with Large Datasets**
```
Error: Memory allocation failed during context formatting
```
**Solution:**
- Reduce query timeframe or scope
- Enable data pagination in configuration
- Increase system memory allocation

#### 4. **Authentication Failures**
```
Error: 401 Unauthorized
```
**Solution:**
- Verify Bearer token format and validity
- Check token expiration and renewal
- Ensure proper Authorization header format

### Debug Mode

Enable comprehensive debugging:

```bash
# Set environment variable
export DEBUG=true
export LOG_LEVEL=DEBUG

# Start server with debug logging
uvicorn main:app --reload --log-level debug
```

### Performance Monitoring

Monitor system performance:

```bash
# Check memory usage
python -c "import psutil; print(f'Memory: {psutil.virtual_memory().percent}%')"

# Monitor API response times
curl -w "@curl-format.txt" -o /dev/null -s "http://localhost:8000/orchestrate"
```

## Performance

### Benchmarks

| Metric | Value | Notes |
|--------|-------|-------|
| Average Response Time | 1.2s | For typical queries |
| Peak Throughput | 50 req/s | With 4 workers |
| Memory Usage | 150MB | Base footprint |
| CPU Usage | 15% | During processing |

### Optimization Tips

1. **Caching**: Implement Redis for frequently accessed data
2. **Connection Pooling**: Use connection pools for external APIs
3. **Async Processing**: Leverage async/await for I/O operations
4. **Resource Limits**: Configure appropriate memory and CPU limits

### Scaling Recommendations

- **Horizontal Scaling**: Deploy multiple instances behind load balancer
- **Database Optimization**: Use read replicas for data-heavy operations
- **CDN Integration**: Cache static responses and common queries
- **Monitoring**: Implement comprehensive APM solution

---

## Interactive API Documentation

After starting the server, visit:
- **Swagger UI**: `http://localhost:8000/docs`
- **ReDoc**: `http://localhost:8000/redoc`

## License

MIT License - see LICENSE file for details.

## Support

For issues and questions:
- Create an issue in the repository
- Check the troubleshooting section above
- Review logs with DEBUG level enabled